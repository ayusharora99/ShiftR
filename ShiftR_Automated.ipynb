{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Means:\n",
    "    def __init__(self, k=7,tol=0.0,max_iter = 300):\n",
    "        self.k = k\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "    def fit(self,data):\n",
    "        self.centroids = {}\n",
    "        for i in range(self.k):\n",
    "            self.centroids[i] = data[i] # Adjust first centroid around 1st Base?\n",
    "            \n",
    "        for i in range(self.max_iter):\n",
    "            print(\"Iteration: \" + str(i))\n",
    "            self.classifications = {}\n",
    "            \n",
    "            for i in range(self.k):\n",
    "                self.classifications[i] = []\n",
    "                \n",
    "            for featureset in data:\n",
    "                distances = [np.linalg.norm(featureset - self.centroids[centroid]) for centroid in self.centroids]\n",
    "                classification = distances.index(min(distances))\n",
    "                self.classifications[classification].append(featureset)\n",
    "                \n",
    "            prev_centroids = dict(self.centroids)\n",
    "            \n",
    "            for classification in self.classifications:\n",
    "                self.centroids[classification] = np.average(self.classifications[classification], axis = 0)\n",
    "            \n",
    "            optimized = True\n",
    "            \n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid - original_centroid)/ original_centroid * 100.0) > self.tol:\n",
    "                    optimized = False\n",
    "                \n",
    "            if optimized:\n",
    "                break\n",
    "                \n",
    "    def predict(self,data):\n",
    "        distances = [np.linalg.norm(data - self.centroids[centroid]) for centroid in self.centroids]\n",
    "        classification = distances.index(min(distances))\n",
    "        return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "    name = input(\"Batter's first and last name: \").split(\" \")\n",
    "    if len(name) == 2:\n",
    "        first_name = name[0].capitalize()\n",
    "        last_name = name[1].capitalize()\n",
    "        print(\"Preprocessing Batted Ball Data for \" + first_name + \" \" + last_name + \"...\")\n",
    "        df = pd.read_csv('BC_College_Data.csv')\n",
    "        batted_balls = df.dropna(subset = ['distance','launch_angle','exit_velocity','hang_time','direction','pitcher_handedness','batter_handedness','hit','play_result','pitcher_handedness','batter_handedness'])\n",
    "\n",
    "        balls_in_play = batted_balls.loc[batted_balls['direction'].abs() <=45]\n",
    "        balls_in_play = balls_in_play.loc[balls_in_play['hit'] == 't']\n",
    "        balls_in_play = balls_in_play.loc[balls_in_play['batter_handedness'] != 'Undefined']\n",
    "        balls_in_play = balls_in_play.loc[balls_in_play['pitcher_handedness'] != 'Undefined']\n",
    "        balls_in_play = balls_in_play[(balls_in_play['play_result'] != 'Undefined')]\n",
    "        balls_in_play = balls_in_play[(balls_in_play['play_result'] != 'HomeRun')]\n",
    "        balls_in_play = balls_in_play[(balls_in_play['play_result'] != 'Sacrifice')]\n",
    "        balls_in_play = balls_in_play[(balls_in_play['play_result'] !=  'FieldersChoice')]\n",
    "        balls_in_play = balls_in_play[(balls_in_play['play_result'] != 'Error')]\n",
    "        balls_in_play = balls_in_play[(balls_in_play['play_result'] != 'BP')]\n",
    "        balls_in_play = balls_in_play[(balls_in_play['hit_type'] != 'Bunt')]\n",
    "        \n",
    "        \n",
    "        balls_in_play.loc[(balls_in_play['pitcher_handedness'] == 'R'), 'pitcher_handedness'] = 1\n",
    "\n",
    "        balls_in_play.loc[(balls_in_play['pitcher_handedness'] == 'L'), 'pitcher_handedness'] = 0\n",
    "\n",
    "        balls_in_play.loc[(balls_in_play['batter_handedness'] == 'R'), 'batter_handedness'] = 1\n",
    "\n",
    "        balls_in_play.loc[(balls_in_play['batter_handedness'] == 'L'), 'batter_handedness'] = 0\n",
    "        \n",
    "        balls_in_play['pitcher_handedness'] = balls_in_play['pitcher_handedness'].astype(int)\n",
    "        balls_in_play['batter_handedness'] = balls_in_play['pitcher_handedness'].astype(int)\n",
    "        \n",
    "        balls_in_play.to_csv('balls_in_play.csv')\n",
    "        \n",
    "        training_data = balls_in_play.select_dtypes(include = ['int64', 'float64'])\n",
    "        training_data['play_result'] = balls_in_play['play_result']\n",
    "        \n",
    "        training_data.loc[(training_data['play_result'] != 'Out'), 'play_result'] = 1\n",
    "        training_data.loc[(training_data['play_result'] == 'Out'), 'play_result'] = 0\n",
    "\n",
    "        training_data['play_result'] = training_data['play_result'].astype(int)\n",
    "        \n",
    "        training_data = training_data.drop(columns = ['id_6digit',\n",
    "                             'pitcher_datraks_id',\n",
    "                             'batter_datraks_id',\n",
    "                             'csv_manager_id',\n",
    "                             'pitch_number',\n",
    "                             'plate_appearance',\n",
    "                             'pitch_of_plate_appearance',\n",
    "                             'outs_on_play',\n",
    "                             'runs_scored',\n",
    "                             'tc_event_id',\n",
    "                             'tc_team_id_2',\n",
    "                             'id',\n",
    "                             'dk_coach_id',\n",
    "                             'id_3',\n",
    "                             'description',\n",
    "                             'tc_team_id'])\n",
    "        \n",
    "        training_data.insert(0, 'batter_name', balls_in_play['batter_name'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        training_data.to_csv(\"training_data.csv\")\n",
    "        \n",
    "        batters = training_data.groupby(\"batter_name\", as_index=False)\n",
    "        batter_dict = dict(iter(batters))\n",
    "        \n",
    "        Batter = batter_dict[str(last_name + ', ' + first_name)]\n",
    "        Batter = Batter.reset_index(drop=True)\n",
    "        \n",
    "        print(first_name + \" \" + last_name + \" has \" + str(len(Batter)) + \" Batted Balls In Play.\")\n",
    "        print()\n",
    "        \n",
    "        print(\"Creating Traditional Field against \" + first_name + \" \" + last_name + \"...\")\n",
    "        \n",
    "        training_data = pd.read_csv(\"training_data.csv\")\n",
    "        training_data = training_data.dropna(subset = ['exit_velocity','distance','hang_time','direction','play_result'])\n",
    "        training_data = training_data.drop(columns = ['Unnamed: 0'])\n",
    "        for i, bip in training_data.iterrows():\n",
    "            if(((training_data.at[i,'distance'] <= 180) and (training_data.at[i,'distance'] >= 2)) and ((training_data.at[i,'direction'] <= 45) and (training_data.at[i,'direction'] >= 25))):\n",
    "                training_data.at[i,'traditional_cluster'] = 3\n",
    "            elif (((training_data.at[i,'distance'] <= 180) and (training_data.at[i,'distance'] >= 1)) and ((training_data.at[i,'direction'] <= 20) and (training_data.at[i,'direction'] >= 0))):\n",
    "                training_data.at[i,'traditional_cluster'] = 4\n",
    "            elif (((training_data.at[i,'distance'] <= 180) and (training_data.at[i,'distance'] >= 5)) and ((training_data.at[i,'direction'] <= -25) and (training_data.at[i,'direction'] >= -45))):\n",
    "                training_data.at[i,'traditional_cluster'] = 5\n",
    "            elif(((training_data.at[i,'distance'] <= 180) and (training_data.at[i,'distance'] >= 9)) and ((training_data.at[i,'direction'] <= 0) and (training_data.at[i,'direction'] >= -20))):\n",
    "                training_data.at[i,'traditional_cluster'] = 6\n",
    "            elif(((training_data.at[i,'distance'] <= 309) and (training_data.at[i,'distance'] >= 210)) and ((training_data.at[i,'direction'] <= -20) and (training_data.at[i,'direction'] >= -45))):\n",
    "                training_data.at[i,'traditional_cluster'] = 7\n",
    "            elif(((training_data.at[i,'distance'] <= 347) and (training_data.at[i,'distance'] >= 225)) and ((training_data.at[i,'direction'] <= 20) and (training_data.at[i,'direction'] >= -20))):\n",
    "                training_data.at[i,'traditional_cluster'] = 8\n",
    "            elif(((training_data.at[i,'distance'] <= 309) and (training_data.at[i,'distance'] >= 210)) and ((training_data.at[i,'direction'] <= 45) and (training_data.at[i,'direction'] >= 20))):\n",
    "                training_data.at[i,'traditional_cluster'] = 9\n",
    "            else:\n",
    "                training_data.at[i,'traditional_cluster'] = 0\n",
    "\n",
    "        training_data.to_csv('training_data.csv')\n",
    "        traditional_none = training_data.loc[training_data['traditional_cluster'] == 0]\n",
    "        traditional_1B = training_data.loc[training_data['traditional_cluster'] == 3]\n",
    "        traditional_2B = training_data.loc[training_data['traditional_cluster'] == 4]\n",
    "        traditional_3B = training_data.loc[training_data['traditional_cluster'] == 5]\n",
    "        traditional_SS = training_data.loc[training_data['traditional_cluster'] == 6]\n",
    "        traditional_LF = training_data.loc[training_data['traditional_cluster'] == 7]\n",
    "        traditional_CF = training_data.loc[training_data['traditional_cluster'] == 8]\n",
    "        traditional_RF = training_data.loc[training_data['traditional_cluster'] == 9]\n",
    "        \n",
    "        traditional_none.to_csv('college_trad_none.csv')\n",
    "        traditional_1B.to_csv('college_trad_1B.csv')\n",
    "        traditional_2B.to_csv('college_trad_2B.csv')\n",
    "        traditional_3B.to_csv('college_trad_3B.csv')\n",
    "        traditional_SS.to_csv('college_trad_SS.csv')\n",
    "        traditional_LF.to_csv('college_trad_LF.csv')\n",
    "        traditional_CF.to_csv('college_trad_CF.csv')\n",
    "        traditional_RF.to_csv('college_trad_RF.csv')\n",
    "        \n",
    "        batters = training_data.groupby(\"batter_name\", as_index=False)\n",
    "        batter_dict = dict(iter(batters))\n",
    "        \n",
    "        Batter = batter_dict[str(last_name + ', ' + first_name)]\n",
    "        \n",
    "        traditional_cluster_0 = Batter.loc[Batter['traditional_cluster'] == 3]\n",
    "        traditional_cluster_1 = Batter.loc[Batter['traditional_cluster'] == 4]\n",
    "        traditional_cluster_2 = Batter.loc[Batter['traditional_cluster'] == 5]\n",
    "        traditional_cluster_3 = Batter.loc[Batter['traditional_cluster'] == 6]\n",
    "        traditional_cluster_4 = Batter.loc[Batter['traditional_cluster'] == 7]\n",
    "        traditional_cluster_5 = Batter.loc[Batter['traditional_cluster'] == 8]\n",
    "        traditional_cluster_6 = Batter.loc[Batter['traditional_cluster'] == 9]\n",
    "        clusters = ['traditional_cluster_0','traditional_cluster_1','traditional_cluster_2','traditional_cluster_3','traditional_cluster_4','traditional_cluster_5','traditional_cluster_6']\n",
    "        \n",
    "        Batter.to_csv('traditional_clusters.csv')\n",
    "        \n",
    "        traditional_cluster_0.to_csv('traditional_cluster_0.csv')\n",
    "        traditional_cluster_1.to_csv('traditional_cluster_1.csv')\n",
    "        traditional_cluster_2.to_csv('traditional_cluster_2.csv')\n",
    "        traditional_cluster_3.to_csv('traditional_cluster_3.csv')\n",
    "        traditional_cluster_4.to_csv('traditional_cluster_4.csv')\n",
    "        traditional_cluster_5.to_csv('traditional_cluster_5.csv')\n",
    "        traditional_cluster_6.to_csv('traditional_cluster_6.csv')\n",
    "        \n",
    "        mean_distances = []\n",
    "        mean_distances.append(traditional_cluster_0['distance'].mean())\n",
    "        mean_distances.append(traditional_cluster_1['distance'].mean())\n",
    "        mean_distances.append(traditional_cluster_2['distance'].mean())\n",
    "        mean_distances.append(traditional_cluster_3['distance'].mean())\n",
    "        mean_distances.append(traditional_cluster_4['distance'].mean())\n",
    "        mean_distances.append(traditional_cluster_5['distance'].mean())\n",
    "        mean_distances.append(traditional_cluster_6['distance'].mean())\n",
    "        \n",
    "        mean_directions = []\n",
    "        mean_directions.append(traditional_cluster_0['direction'].mean())\n",
    "        mean_directions.append(traditional_cluster_1['direction'].mean())\n",
    "        mean_directions.append(traditional_cluster_2['direction'].mean())\n",
    "        mean_directions.append(traditional_cluster_3['direction'].mean())\n",
    "        mean_directions.append(traditional_cluster_4['direction'].mean())\n",
    "        mean_directions.append(traditional_cluster_5['direction'].mean())\n",
    "        \n",
    "        mean_hits = []\n",
    "        mean_hits.append(traditional_cluster_0['play_result'].mean())\n",
    "        mean_hits.append(traditional_cluster_1['play_result'].mean())\n",
    "        mean_hits.append(traditional_cluster_2['play_result'].mean())\n",
    "        mean_hits.append(traditional_cluster_3['play_result'].mean())\n",
    "        mean_hits.append(traditional_cluster_4['play_result'].mean())\n",
    "        mean_hits.append(traditional_cluster_5['play_result'].mean())\n",
    "        mean_hits.append(traditional_cluster_6['play_result'].mean())\n",
    "        mean_directions.append(traditional_cluster_6['direction'].mean())\n",
    "        \n",
    "        cluster_means = pd.DataFrame()\n",
    "        cluster_means['cluster'] = clusters\n",
    "        cluster_means['distance'] = mean_distances\n",
    "        cluster_means['direction'] = mean_directions\n",
    "        #cluster_means['play_result'] = mean_hits\n",
    "        \n",
    "        print('Traditional Fielder Positions: ')\n",
    "        print(cluster_means)\n",
    "        \n",
    "        cluster_means.to_csv('traditional_cluster_means.csv')\n",
    "        \n",
    "        print()\n",
    "        print(\"Creating Optimal Shift Against \" + first_name + \" \" + last_name)\n",
    "        \n",
    "        location = Batter[['distance','direction']]\n",
    "        location_scaled = preprocessing.scale(location)\n",
    "        clf = K_Means()\n",
    "        clf.fit(location_scaled)\n",
    "        Batter = Batter.reset_index(drop=True)\n",
    "#         for i, bip in Batter.iterrows():\n",
    "#             Batter.at[i,'custom_cluster'] = clf.predict(location_scaled[i])\n",
    "            \n",
    "        kmeans = KMeans(n_clusters = 7)\n",
    "        groups = kmeans.fit_predict(location_scaled)\n",
    "        Batter['custom_cluster'] = groups\n",
    "        Batter.to_csv('clusters.csv')\n",
    "        \n",
    "        cluster_0 = Batter.loc[Batter['custom_cluster'] == 0]\n",
    "        cluster_1 = Batter.loc[Batter['custom_cluster'] == 1]\n",
    "        cluster_2 = Batter.loc[Batter['custom_cluster'] == 2]\n",
    "        cluster_3 = Batter.loc[Batter['custom_cluster'] == 3]\n",
    "        cluster_4 = Batter.loc[Batter['custom_cluster'] == 4]\n",
    "        cluster_5 = Batter.loc[Batter['custom_cluster'] == 5]\n",
    "        cluster_6 = Batter.loc[Batter['custom_cluster'] == 6]\n",
    "\n",
    "\n",
    "        custom_clusters = ['cluster_0','cluster_1','cluster_2','cluster_3','cluster_4','cluster_5','cluster_6']\n",
    "        \n",
    "        cluster_0.to_csv('cluster_0.csv')\n",
    "        cluster_1.to_csv('cluster_1.csv')\n",
    "        cluster_2.to_csv('cluster_2.csv')\n",
    "        cluster_3.to_csv('cluster_3.csv')\n",
    "        cluster_4.to_csv('cluster_4.csv')\n",
    "        cluster_5.to_csv('cluster_5.csv')\n",
    "        \n",
    "        mean_distances = []\n",
    "        mean_distances.append(cluster_0['distance'].mean())\n",
    "        mean_distances.append(cluster_1['distance'].mean())\n",
    "        mean_distances.append(cluster_2['distance'].mean())\n",
    "        mean_distances.append(cluster_3['distance'].mean())\n",
    "        mean_distances.append(cluster_4['distance'].mean())\n",
    "        mean_distances.append(cluster_5['distance'].mean())\n",
    "        mean_distances.append(cluster_6['distance'].mean())\n",
    "        \n",
    "        mean_directions = []\n",
    "        mean_directions.append(cluster_0['direction'].mean())\n",
    "        mean_directions.append(cluster_1['direction'].mean())\n",
    "        mean_directions.append(cluster_2['direction'].mean())\n",
    "        mean_directions.append(cluster_3['direction'].mean())\n",
    "        mean_directions.append(cluster_4['direction'].mean())\n",
    "        mean_directions.append(cluster_5['direction'].mean())\n",
    "        mean_directions.append(cluster_6['direction'].mean())\n",
    "        \n",
    "        mean_hits = []\n",
    "        mean_hits.append(cluster_0['play_result'].mean())\n",
    "        mean_hits.append(cluster_1['play_result'].mean())\n",
    "        mean_hits.append(cluster_2['play_result'].mean())\n",
    "        mean_hits.append(cluster_3['play_result'].mean())\n",
    "        mean_hits.append(cluster_4['play_result'].mean())\n",
    "        mean_hits.append(cluster_5['play_result'].mean())\n",
    "        mean_hits.append(cluster_6['play_result'].mean())\n",
    "\n",
    "        cluster_means = pd.DataFrame()\n",
    "        cluster_means['cluster'] = custom_clusters\n",
    "        cluster_means['distance'] = mean_distances\n",
    "        cluster_means['direction'] = mean_directions\n",
    "        #cluster_means['play_result'] = mean_hits\n",
    "        clusters = ['cluster_0','cluster_1','cluster_2','cluster_3','cluster_4','cluster_5','cluster_6']\n",
    "        \n",
    "        print('Shifted Fielder Positions: ')\n",
    "        print(cluster_means)\n",
    "        \n",
    "        for i,row in cluster_means.iterrows():\n",
    "            if(cluster_means.at[i,'distance'] < 90):\n",
    "                cluster_means.at[i,'distance'] = 90\n",
    "        \n",
    "        cluster_means.to_csv('cluster_means.csv')\n",
    "        \n",
    "        print()\n",
    "        print(\"Assessing Traditional Field against \" + first_name + \" \" + last_name + \"...\")\n",
    "        \n",
    "        clusters = pd.read_csv('clusters.csv')\n",
    "        college_trad_none = pd.read_csv('college_trad_none.csv')\n",
    "        college_trad_1B = pd.read_csv('college_trad_1B.csv')\n",
    "        college_trad_2B = pd.read_csv('college_trad_2B.csv')\n",
    "        college_trad_3B = pd.read_csv('college_trad_3B.csv') \n",
    "        college_trad_SS = pd.read_csv('college_trad_SS.csv') \n",
    "        college_trad_LF = pd.read_csv('college_trad_LF.csv') \n",
    "        college_trad_CF = pd.read_csv('college_trad_CF.csv') \n",
    "        college_trad_RF = pd.read_csv('college_trad_RF.csv') \n",
    "        \n",
    "        clusters = clusters.drop(columns = ['Unnamed: 0'])\n",
    "        \n",
    "        college_trad_none_lr = college_trad_none[['exit_velocity','hang_time','play_result']]\n",
    "        college_trad_1B_lr = college_trad_1B[['exit_velocity','hang_time','play_result']]\n",
    "        college_trad_2B_lr = college_trad_2B[['exit_velocity','hang_time','play_result']]\n",
    "        college_trad_3B_lr = college_trad_3B[['exit_velocity','hang_time','play_result']]\n",
    "        college_trad_SS_lr = college_trad_SS[['exit_velocity','hang_time','play_result']]\n",
    "        college_trad_LF_lr = college_trad_LF[['exit_velocity','hang_time','play_result']]\n",
    "        college_trad_CF_lr = college_trad_CF[['exit_velocity','hang_time','play_result']]\n",
    "        college_trad_RF_lr = college_trad_RF[['exit_velocity','hang_time','play_result']]\n",
    "        \n",
    "        traditional_none = clusters.loc[clusters['traditional_cluster'] == 0]\n",
    "        traditional_1B = clusters.loc[clusters['traditional_cluster'] == 3]\n",
    "        traditional_2B = clusters.loc[clusters['traditional_cluster'] == 4]\n",
    "        traditional_3B = clusters.loc[clusters['traditional_cluster'] == 5]\n",
    "        traditional_SS = clusters.loc[clusters['traditional_cluster'] == 6]\n",
    "        traditional_LF = clusters.loc[clusters['traditional_cluster'] == 7]\n",
    "        traditional_CF = clusters.loc[clusters['traditional_cluster'] == 8]\n",
    "        traditional_RF = clusters.loc[clusters['traditional_cluster'] == 9]\n",
    "        \n",
    "        traditional_none_lr = traditional_none[['exit_velocity','hang_time','play_result']]\n",
    "        traditional_1B_lr = traditional_1B[['exit_velocity','hang_time','play_result']]\n",
    "        traditional_2B_lr = traditional_2B[['exit_velocity','hang_time','play_result']]\n",
    "        traditional_3B_lr = traditional_3B[['exit_velocity','hang_time','play_result']]\n",
    "        traditional_SS_lr = traditional_SS[['exit_velocity','hang_time','play_result']]\n",
    "        traditional_LF_lr = traditional_LF[['exit_velocity','hang_time','play_result']]\n",
    "        traditional_CF_lr = traditional_CF[['exit_velocity','hang_time','play_result']]\n",
    "        traditional_RF_lr = traditional_RF[['exit_velocity','hang_time','play_result']]\n",
    "        \n",
    "        shift_1B = clusters.loc[clusters['custom_cluster'] == 3]\n",
    "        shift_RF = clusters.loc[clusters['custom_cluster'] == 0]\n",
    "        shift_LF = clusters.loc[clusters['custom_cluster'] == 4]\n",
    "        shift_2B = clusters.loc[clusters['custom_cluster'] == 1]\n",
    "        shift_SS = clusters.loc[clusters['custom_cluster'] == 2]\n",
    "        shift_3B = clusters.loc[clusters['custom_cluster'] == 5]\n",
    "        shift_CF = clusters.loc[clusters['custom_cluster'] == 6]\n",
    "        \n",
    "        shift_1B_lr = shift_1B[['exit_velocity','hang_time','play_result']]\n",
    "        shift_2B_lr = shift_2B[['exit_velocity','hang_time','play_result']]\n",
    "        shift_3B_lr = shift_3B[['exit_velocity','hang_time','play_result']]\n",
    "        shift_SS_lr = shift_SS[['exit_velocity','hang_time','play_result']]\n",
    "        shift_LF_lr = shift_LF[['exit_velocity','hang_time','play_result']]\n",
    "        shift_CF_lr = shift_CF[['exit_velocity','hang_time','play_result']]\n",
    "        shift_RF_lr = shift_RF[['exit_velocity','hang_time','play_result']]\n",
    "        \n",
    "        # No mans land Traditional\n",
    "        bip = len(traditional_none_lr)\n",
    "        X = preprocessing.scale(college_trad_none_lr[['exit_velocity','hang_time']])\n",
    "        y = college_trad_none_lr['play_result']\n",
    "        clf_none = LogisticRegression(random_state=42).fit(X, y)\n",
    "        batter_X = preprocessing.scale(traditional_none_lr[['exit_velocity','hang_time']])\n",
    "        traditional_none = clf_none.predict_proba(batter_X)\n",
    "        out_probs = []\n",
    "        for probs in traditional_none:\n",
    "            out_probs.append(probs[0])\n",
    "        traditional_none_lr['traditional_out_prob'] = out_probs\n",
    "        expected_outs = sum(traditional_none_lr['traditional_out_prob'])\n",
    "        trad_none_outs = bip - sum(traditional_none_lr['play_result'])\n",
    "        expected_out_prob = expected_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip) + ', '+ 'Traditional Outs: ' + str(trad_none_outs) + ', ' +\" Expected Outs: \" + str(expected_outs) + ', ' + \" Traditional Out Probability: \" + str(expected_out_prob*100) + '%')\n",
    "    \n",
    "        # 1B Traditional\n",
    "        bip = len(traditional_1B_lr)\n",
    "        X = preprocessing.scale(college_trad_1B_lr[['exit_velocity','hang_time']])\n",
    "        y = college_trad_1B_lr['play_result']\n",
    "        clf_1B = LogisticRegression(random_state=42).fit(X, y)\n",
    "        batter_X = preprocessing.scale(traditional_1B_lr[['exit_velocity','hang_time']])\n",
    "        traditional_1B = clf_1B.predict_proba(batter_X)\n",
    "        out_probs = []\n",
    "        for probs in traditional_1B:\n",
    "            out_probs.append(probs[0])\n",
    "        traditional_1B_lr['traditional_out_prob'] = out_probs\n",
    "        expected_outs = sum(traditional_1B_lr['traditional_out_prob'])\n",
    "        trad_1B_outs = bip - sum(traditional_1B_lr['play_result'])\n",
    "        expected_out_prob = expected_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip) + ', '+ 'Traditional Outs: ' + str(trad_1B_outs) + ', ' +\" Expected Outs: \" + str(expected_outs) + ', ' + \" Traditional Out Probability: \" + str(expected_out_prob*100) + '%')\n",
    "    \n",
    "        # 2B Traditional\n",
    "        bip = len(traditional_2B_lr)\n",
    "        X = preprocessing.scale(college_trad_2B_lr[['exit_velocity','hang_time']])\n",
    "        y = college_trad_2B_lr['play_result']\n",
    "        clf_2B = LogisticRegression(random_state=42).fit(X, y)\n",
    "        batter_X = preprocessing.scale(traditional_2B_lr[['exit_velocity','hang_time']])\n",
    "        traditional_2B = clf_2B.predict_proba(batter_X)\n",
    "        out_probs = []\n",
    "        for probs in traditional_2B:\n",
    "            out_probs.append(probs[0])\n",
    "        traditional_2B_lr['traditional_out_prob'] = out_probs\n",
    "        expected_outs = sum(traditional_2B_lr['traditional_out_prob'])\n",
    "        trad_2B_outs = bip - sum(traditional_2B_lr['play_result'])\n",
    "        expected_out_prob = expected_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip) + ', '+ 'Traditional Outs: ' + str(trad_2B_outs) + ', ' + \" Expected Outs: \" + str(expected_outs) + ', ' + \" Traditional Out Probability: \" + str(expected_out_prob*100) + '%')\n",
    "    \n",
    "        # 3B Traditional \n",
    "        bip = len(traditional_3B_lr)\n",
    "        X = preprocessing.scale(college_trad_3B_lr[['exit_velocity','hang_time']])\n",
    "        y = college_trad_3B_lr['play_result']\n",
    "        clf_3B = LogisticRegression(random_state=42).fit(X, y)\n",
    "        batter_X = preprocessing.scale(traditional_3B_lr[['exit_velocity','hang_time']])\n",
    "        traditional_3B = clf_3B.predict_proba(batter_X)\n",
    "        out_probs = []\n",
    "        for probs in traditional_3B:\n",
    "            out_probs.append(probs[0])\n",
    "        traditional_3B_lr['traditional_out_prob'] = out_probs\n",
    "        expected_outs = sum(traditional_3B_lr['traditional_out_prob'])\n",
    "        trad_3B_outs = bip - sum(traditional_3B_lr['play_result'])\n",
    "        expected_out_prob = expected_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip) + ', '+ 'Traditional Outs: ' + str(trad_3B_outs) + ', ' + \" Expected Outs: \" + str(expected_outs) + ', ' + \" Traditional Out Probability: \" + str(expected_out_prob*100) + '%')\n",
    "        \n",
    "        # SS Traditional\n",
    "        bip = len(traditional_SS_lr)\n",
    "        X = preprocessing.scale(college_trad_SS_lr[['exit_velocity','hang_time']])\n",
    "        y = college_trad_SS_lr['play_result']\n",
    "        clf_SS = LogisticRegression(random_state=42).fit(X, y)\n",
    "        batter_X = preprocessing.scale(traditional_SS_lr[['exit_velocity','hang_time']])\n",
    "        traditional_SS = clf_SS.predict_proba(batter_X)\n",
    "        out_probs = []\n",
    "        for probs in traditional_SS:\n",
    "            out_probs.append(probs[0])\n",
    "        traditional_SS_lr['traditional_out_prob'] = out_probs\n",
    "        expected_outs = sum(traditional_SS_lr['traditional_out_prob'])\n",
    "        trad_SS_outs = bip - sum(traditional_SS_lr['play_result'])\n",
    "        expected_out_prob = expected_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip) + ', '+ 'Traditional Outs: ' + str(trad_SS_outs) + ', ' + \" Expected Outs: \" + str(expected_outs) + ', ' + \" Traditional Out Probability: \" + str(expected_out_prob*100) + '%')\n",
    "    \n",
    "        # LF Traditional \n",
    "        bip = len(traditional_LF_lr)\n",
    "        X = preprocessing.scale(college_trad_LF_lr[['exit_velocity','hang_time']])\n",
    "        y = college_trad_LF_lr['play_result']\n",
    "        clf_LF = LogisticRegression(random_state=42).fit(X, y)\n",
    "        batter_X = preprocessing.scale(traditional_LF_lr[['exit_velocity','hang_time']])\n",
    "        traditional_LF = clf_LF.predict_proba(batter_X)\n",
    "        out_probs = []\n",
    "        for probs in traditional_LF:\n",
    "            out_probs.append(probs[0])\n",
    "        traditional_LF_lr['traditional_out_prob'] = out_probs\n",
    "        expected_outs = sum(traditional_LF_lr['traditional_out_prob'])\n",
    "        trad_LF_outs = bip - sum(traditional_LF_lr['play_result'])\n",
    "        expected_out_prob = expected_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip) + ', '+ 'Traditional Outs: ' + str(trad_LF_outs) + ', ' + \" Expected Outs: \" + str(expected_outs) + ', ' + \" Traditional Out Probability: \" + str(expected_out_prob*100) + '%')\n",
    "        \n",
    "        # CF Traditional\n",
    "        bip = len(traditional_CF_lr)\n",
    "        X = preprocessing.scale(college_trad_CF_lr[['exit_velocity','hang_time']])\n",
    "        y = college_trad_CF_lr['play_result']\n",
    "        clf_CF = LogisticRegression(random_state=42).fit(X, y)\n",
    "        batter_X = preprocessing.scale(traditional_CF_lr[['exit_velocity','hang_time']])\n",
    "        traditional_CF = clf_CF.predict_proba(batter_X)\n",
    "        out_probs = []\n",
    "        for probs in traditional_CF:\n",
    "            out_probs.append(probs[0])\n",
    "        traditional_CF_lr['traditional_out_prob'] = out_probs\n",
    "        expected_outs = sum(traditional_CF_lr['traditional_out_prob'])\n",
    "        trad_CF_outs = bip - sum(traditional_CF_lr['play_result'])\n",
    "        expected_out_prob = expected_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip) + ', '+ 'Traditional Outs: ' + str(trad_CF_outs) + ', ' + \" Expected Outs: \" + str(expected_outs) + ', ' + \" Traditional Out Probability: \" + str(expected_out_prob*100) + '%')\n",
    "    \n",
    "        # RF Traditional\n",
    "        bip = len(traditional_RF_lr)\n",
    "        X = preprocessing.scale(college_trad_RF_lr[['exit_velocity','hang_time']])\n",
    "        y = college_trad_RF_lr['play_result']\n",
    "        clf_RF = LogisticRegression(random_state=42).fit(X, y)\n",
    "        batter_X = preprocessing.scale(traditional_RF_lr[['exit_velocity','hang_time']])\n",
    "        traditional_RF = clf_RF.predict_proba(batter_X)\n",
    "        out_probs = []\n",
    "        for probs in traditional_RF:\n",
    "            out_probs.append(probs[0])\n",
    "        traditional_RF_lr['traditional_out_prob'] = out_probs\n",
    "        expected_outs = sum(traditional_RF_lr['traditional_out_prob'])\n",
    "        trad_RF_outs = bip - sum(traditional_RF_lr['play_result'])\n",
    "        expected_out_prob = expected_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip) + ', '+ 'Traditional Outs: ' + str(trad_RF_outs) + ', ' + \" Expected Outs: \" + str(expected_outs) + ', ' + \" Traditional Out Probability: \" + str(expected_out_prob*100) + '%')\n",
    "    \n",
    "        bip = len(clusters)\n",
    "        print(\"Total BIP: \" + str(bip))\n",
    "        trad_outs = trad_1B_outs + trad_2B_outs + trad_3B_outs + trad_SS_outs + trad_LF_outs + trad_CF_outs + trad_RF_outs + trad_none_outs\n",
    "        print(\"Traditional Field Outs: \" + str(trad_outs))\n",
    "        print(\"Traditional Field Out Probability: \" + str((trad_outs/bip)*100) + \"%\")\n",
    "        \n",
    "        \n",
    "        print()\n",
    "        print(\"Assessing Shifted Field against \" + first_name + \" \" + last_name + \"...\")\n",
    "        \n",
    "        # 1B Shift\n",
    "        bip = len(shift_1B_lr)\n",
    "        X = preprocessing.scale(shift_1B_lr[['exit_velocity','hang_time']])\n",
    "        shift_1B = clf_1B.predict_proba(X)\n",
    "        out_probs = []\n",
    "        for probs in shift_1B:\n",
    "            out_probs.append(probs[0])\n",
    "        shift_1B_lr['shift_out_prob'] = out_probs\n",
    "        shift_1B_outs = sum(shift_1B_lr['shift_out_prob'])\n",
    "        trad_1B_outs = bip - sum(shift_1B_lr['play_result'])\n",
    "        trad_1B_out_prob = trad_1B_outs / bip\n",
    "        shifted_1B_out_prob = shift_1B_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip))\n",
    "        # print('Traditional Outs: ' + str(trad_1B_outs) + ', ' + 'Traditional Out Probability: ' + str(trad_1B_out_prob*100) + \" %\")\n",
    "        # print( \"Shifted Outs: \" + str(shift_1B_outs) + ', ' + \" Shifted Out Probability: \" + str(shifted_1B_out_prob*100) + ' %')\n",
    "    \n",
    "        # 2B Shift\n",
    "        bip = len(shift_2B_lr)\n",
    "        X = preprocessing.scale(shift_2B_lr[['exit_velocity','hang_time']])\n",
    "        shift_2B = clf_2B.predict_proba(X)\n",
    "        out_probs = []\n",
    "        for probs in shift_2B:\n",
    "            out_probs.append(probs[0])\n",
    "        shift_2B_lr['shift_out_prob'] = out_probs\n",
    "        shift_2B_outs = sum(shift_2B_lr['shift_out_prob'])\n",
    "        trad_2B_outs = bip - sum(shift_2B_lr['play_result'])\n",
    "        trad_2B_out_prob = trad_2B_outs / bip\n",
    "        shifted_2B_out_prob = shift_2B_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip))\n",
    "        # print('Traditional Outs: ' + str(trad_2B_outs) + ', ' + 'Traditional Out Probability: ' + str(trad_2B_out_prob*100) + \" %\")\n",
    "        # print( \"Shifted Outs: \" + str(shift_2B_outs) + ', ' + \" Shifted Out Probability: \" + str(shifted_2B_out_prob*100) + ' %')\n",
    "    \n",
    "        # 3B Shift\n",
    "        bip = len(shift_3B_lr)\n",
    "        X = preprocessing.scale(shift_3B_lr[['exit_velocity','hang_time']])\n",
    "        shift_3B = clf_3B.predict_proba(X)\n",
    "        out_probs = []\n",
    "        for probs in shift_3B:\n",
    "            out_probs.append(probs[0])\n",
    "        shift_3B_lr['shift_out_prob'] = out_probs\n",
    "        shift_3B_outs = sum(shift_3B_lr['shift_out_prob'])\n",
    "        trad_3B_outs = bip - sum(shift_3B_lr['play_result'])\n",
    "        trad_3B_out_prob = trad_3B_outs / bip\n",
    "        shifted_3B_out_prob = shift_3B_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip))\n",
    "        # print('Traditional Outs: ' + str(trad_3B_outs) + ', ' + 'Traditional Out Probability: ' + str(trad_3B_out_prob*100) + \" %\")\n",
    "        # print( \"Shifted Outs: \" + str(shift_3B_outs) + ', ' + \" Shifted Out Probability: \" + str(shifted_3B_out_prob*100) + ' %')\n",
    "    \n",
    "        # SS Shift\n",
    "        bip = len(shift_SS_lr)\n",
    "        X = preprocessing.scale(shift_SS_lr[['exit_velocity','hang_time']])\n",
    "        shift_SS = clf_SS.predict_proba(X)\n",
    "        out_probs = []\n",
    "        for probs in shift_SS:\n",
    "            out_probs.append(probs[0])\n",
    "        shift_SS_lr['shift_out_prob'] = out_probs\n",
    "        shift_SS_outs = sum(shift_SS_lr['shift_out_prob'])\n",
    "        trad_SS_outs = bip - sum(shift_SS_lr['play_result'])\n",
    "        trad_SS_out_prob = trad_SS_outs / bip\n",
    "        shifted_SS_out_prob = shift_SS_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip))\n",
    "        # print('Traditional Outs: ' + str(trad_SS_outs) + ', ' + 'Traditional Out Probability: ' + str(trad_SS_out_prob*100) + \" %\")\n",
    "        # print( \"Shifted Outs: \" + str(shift_SS_outs) + ', ' + \" Shifted Out Probability: \" + str(shifted_SS_out_prob*100) + ' %')\n",
    "    \n",
    "        # LF Shift\n",
    "        bip = len(shift_LF_lr)\n",
    "        X = preprocessing.scale(shift_LF_lr[['exit_velocity','hang_time']])\n",
    "        shift_LF = clf_LF.predict_proba(X)\n",
    "        out_probs = []\n",
    "        for probs in shift_LF:\n",
    "            out_probs.append(probs[0])\n",
    "        shift_LF_lr['shift_out_prob'] = out_probs\n",
    "        shift_LF_outs = sum(shift_LF_lr['shift_out_prob'])\n",
    "        trad_LF_outs = bip - sum(shift_LF_lr['play_result'])\n",
    "        trad_LF_out_prob = trad_LF_outs / bip\n",
    "        shifted_LF_out_prob = shift_LF_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip))\n",
    "        # print('Traditional Outs: ' + str(trad_LF_outs) + ', ' + 'Traditional Out Probability: ' + str(trad_LF_out_prob*100) + \" %\")\n",
    "        # print( \"Shifted Outs: \" + str(shift_LF_outs) + ', ' + \" Shifted Out Probability: \" + str(shifted_LF_out_prob*100) + ' %')\n",
    "    \n",
    "        # CF Shift\n",
    "        bip = len(shift_CF_lr)\n",
    "        X = preprocessing.scale(shift_CF_lr[['exit_velocity','hang_time']])\n",
    "        shift_CF = clf_CF.predict_proba(X)\n",
    "        out_probs = []\n",
    "        for probs in shift_CF:\n",
    "            out_probs.append(probs[0])\n",
    "        shift_CF_lr['shift_out_prob'] = out_probs\n",
    "        shift_CF_outs = sum(shift_CF_lr['shift_out_prob'])\n",
    "        trad_CF_outs = bip - sum(shift_CF_lr['play_result'])\n",
    "        trad_CF_out_prob = trad_CF_outs / bip\n",
    "        shifted_CF_out_prob = shift_CF_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip))\n",
    "        # print('Traditional Outs: ' + str(trad_CF_outs) + ', ' + 'Traditional Out Probability: ' + str(trad_CF_out_prob*100) + \" %\")\n",
    "        # print( \"Shifted Outs: \" + str(shift_CF_outs) + ', ' + \" Shifted Out Probability: \" + str(shifted_CF_out_prob*100) + ' %')\n",
    "    \n",
    "        # RF Shift\n",
    "        bip = len(shift_RF_lr)\n",
    "        X = preprocessing.scale(shift_RF_lr[['exit_velocity','hang_time']])\n",
    "        shift_RF = clf_RF.predict_proba(X)\n",
    "        out_probs = []\n",
    "        for probs in shift_RF:\n",
    "            out_probs.append(probs[0])\n",
    "        shift_RF_lr['shift_out_prob'] = out_probs\n",
    "        shift_RF_outs = sum(shift_RF_lr['shift_out_prob'])\n",
    "        trad_RF_outs = bip - sum(shift_RF_lr['play_result'])\n",
    "        trad_RF_out_prob = trad_RF_outs / bip\n",
    "        shifted_RF_out_prob = shift_RF_outs / bip\n",
    "\n",
    "        # print(\"BIP: \" + str(bip))\n",
    "        # print('Traditional Outs: ' + str(trad_RF_outs) + ', ' + 'Traditional Out Probability: ' + str(trad_RF_out_prob*100) + \" %\")\n",
    "        # print( \"Shifted Outs: \" + str(shift_RF_outs) + ', ' + \" Shifted Out Probability: \" + str(shifted_RF_out_prob*100) + ' %')\n",
    "    \n",
    "        bip = len(clusters)\n",
    "        print(\"Total BIP: \" + str(bip))\n",
    "        shift_outs = shift_1B_outs + shift_2B_outs + shift_3B_outs + shift_SS_outs + shift_LF_outs + shift_CF_outs + shift_RF_outs\n",
    "        print(\"Shifted Field Outs: \" + str(shift_outs))\n",
    "        print(\"Shifted Field Out Probability: \" + str((shift_outs/bip)*100) + \"%\")\n",
    "        print()\n",
    "        \n",
    "        if shift_outs > trad_outs:\n",
    "            print(\"Shift Away!\")\n",
    "        else:\n",
    "            print(\"Standardize Away!\")\n",
    "    \n",
    "    else:\n",
    "        print(\"ERROR: Please enter batter's first and last name.\")\n",
    "        print(\"For example: Mike Trout\")\n",
    "        fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batter's first and last name: bobby seymour\n",
      "Preprocessing Batted Ball Data for Bobby Seymour...\n",
      "Bobby Seymour has 298 Batted Balls In Play.\n",
      "\n",
      "Creating Traditional Field against Bobby Seymour...\n",
      "Traditional Fielder Positions: \n",
      "                 cluster    distance  direction\n",
      "0  traditional_cluster_0   45.815894  32.164125\n",
      "1  traditional_cluster_1   58.883680  11.026881\n",
      "2  traditional_cluster_2   62.867419 -39.612815\n",
      "3  traditional_cluster_3   50.711766  -8.743533\n",
      "4  traditional_cluster_4  257.120429 -26.171712\n",
      "5  traditional_cluster_5  301.760833  -2.013215\n",
      "6  traditional_cluster_6  228.900389  25.002337\n",
      "\n",
      "Creating Optimal Shift Against Bobby Seymour\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 9\n",
      "Shifted Fielder Positions: \n",
      "     cluster    distance  direction\n",
      "0  cluster_0  323.004209   9.797693\n",
      "1  cluster_1   24.897095   4.432497\n",
      "2  cluster_2  155.940330   7.695457\n",
      "3  cluster_3  257.014600 -16.775246\n",
      "4  cluster_4  187.618232  28.051380\n",
      "5  cluster_5   45.029403 -22.503128\n",
      "6  cluster_6   22.061180  27.488669\n",
      "\n",
      "Assessing Traditional Field against Bobby Seymour...\n",
      "Total BIP: 298\n",
      "Traditional Field Outs: 177\n",
      "Traditional Field Out Probability: 59.395973154362416%\n",
      "\n",
      "Assessing Shifted Field against Bobby Seymour...\n",
      "Total BIP: 298\n",
      "Shifted Field Outs: 197.24098797108059\n",
      "Shifted Field Out Probability: 66.1882509970069%\n",
      "\n",
      "Shift Away!\n"
     ]
    }
   ],
   "source": [
    "fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
